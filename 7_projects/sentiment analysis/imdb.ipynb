{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 15,
      "outputs": [],
      "source": "import torch\nfrom torchtext import data\nfrom torchtext import datasets\nimport random\n\nSEED \u003d 1234\ntorch.manual_seed(SEED)\ntorch.backends.cudnn.deterministic \u003d True\n\nTEXT \u003d data.Field(lower\u003dTrue) # batch_first \u003d False\nLABEL \u003d data.LabelField(dtype \u003d torch.float)\n\ntrain_data, test_data \u003d datasets.IMDB.splits(TEXT, LABEL)\ntrain_data, valid_data \u003d train_data.split(random_state \u003d random.seed(SEED))",
      "metadata": {
        "pycharm": {
          "metadata": false,
          "name": "#%%\n",
          "is_executing": false
        }
      }
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "outputs": [],
      "source": "MAX_VOCAB_SIZE \u003d 25000\n\nTEXT.build_vocab(train_data, max_size \u003d MAX_VOCAB_SIZE)\nLABEL.build_vocab(train_data)",
      "metadata": {
        "pycharm": {
          "metadata": false,
          "name": "#%%\n",
          "is_executing": false
        }
      }
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "outputs": [
        {
          "name": "stdout",
          "text": [
            "Unique tokens in TEXT vocabulary: 25002",
            "\n",
            "Unique tokens in LABEL vocabulary: 2",
            "\n"
          ],
          "output_type": "stream"
        }
      ],
      "source": "print(f\"Unique tokens in TEXT vocabulary: {len(TEXT.vocab)}\")\nprint(f\"Unique tokens in LABEL vocabulary: {len(LABEL.vocab)}\")",
      "metadata": {
        "pycharm": {
          "metadata": false,
          "name": "#%%\n",
          "is_executing": false
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": "Why is the vocab size 25002 and not 25000?\n \nOne of the addition tokens is the `\u003cunk\u003e` token and the other is a `\u003cpad\u003e` token.",
      "metadata": {
        "pycharm": {
          "metadata": false
        }
      }
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "outputs": [
        {
          "name": "stdout",
          "text": [
            "[(\u0027the\u0027, 226285), (\u0027a\u0027, 111649), (\u0027and\u0027, 110957), (\u0027of\u0027, 101035), (\u0027to\u0027, 93797), (\u0027is\u0027, 72980), (\u0027in\u0027, 63221), (\u0027i\u0027, 49127), (\u0027this\u0027, 48869), (\u0027that\u0027, 46360), (\u0027it\u0027, 45743), (\u0027/\u003e\u003cbr\u0027, 35752), (\u0027was\u0027, 32947), (\u0027as\u0027, 31489), (\u0027for\u0027, 30174), (\u0027with\u0027, 29730), (\u0027but\u0027, 27837), (\u0027on\u0027, 22107), (\u0027movie\u0027, 21639), (\u0027are\u0027, 20269)]",
            "\n",
            "[\u0027\u003cunk\u003e\u0027, \u0027\u003cpad\u003e\u0027, \u0027the\u0027, \u0027a\u0027, \u0027and\u0027, \u0027of\u0027, \u0027to\u0027, \u0027is\u0027, \u0027in\u0027, \u0027i\u0027]",
            "\n"
          ],
          "output_type": "stream"
        }
      ],
      "source": "print(TEXT.vocab.freqs.most_common(20))\nprint(TEXT.vocab.itos[:10])",
      "metadata": {
        "pycharm": {
          "metadata": false,
          "name": "#%%\n",
          "is_executing": false
        }
      }
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "outputs": [],
      "source": "BATCH_SIZE \u003d 64\n\ndevice \u003d torch.device(\u0027cuda\u0027 if torch.cuda.is_available() else \u0027cpu\u0027)\n\ntrain_iterator, valid_iterator, test_iterator \u003d data.BucketIterator.splits(\n    (train_data, valid_data, test_data), \n    batch_size \u003d BATCH_SIZE,\n    device \u003d device)",
      "metadata": {
        "pycharm": {
          "metadata": false,
          "name": "#%%\n",
          "is_executing": false
        }
      }
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "outputs": [],
      "source": "import torch.nn as nn\n\nclass RNN(nn.Module):\n    def __init__(self, input_dim, embedding_dim, hidden_dim, output_dim):\n        \n        super().__init__()\n        self.embedding \u003d nn.Embedding(input_dim, embedding_dim)    \n        self.rnn \u003d nn.RNN(embedding_dim, hidden_dim)\n        self.fc \u003d nn.Linear(hidden_dim, output_dim)\n        \n    def forward(self, text):\n        #text \u003d [sent len, batch size]\n        embedded \u003d self.embedding(text) #[sent len, batch size, emb dim]\n        output, hidden \u003d self.rnn(embedded)\n        #output: [sent len, batch size, hid dim]\n        #hidden: [1, batch size, hid dim]\n        assert torch.equal(output[-1,:,:], hidden.squeeze(0))\n        \n        return self.fc(hidden.squeeze(0))\n\n",
      "metadata": {
        "pycharm": {
          "metadata": false,
          "name": "#%%\n",
          "is_executing": false
        }
      }
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "outputs": [],
      "source": "INPUT_DIM \u003d len(TEXT.vocab)\nEMBEDDING_DIM \u003d 100\nHIDDEN_DIM \u003d 256\nOUTPUT_DIM \u003d 1\n\nmodel \u003d RNN(INPUT_DIM, EMBEDDING_DIM, HIDDEN_DIM, OUTPUT_DIM).to(device)",
      "metadata": {
        "pycharm": {
          "metadata": false,
          "name": "#%%\n",
          "is_executing": false
        }
      }
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "outputs": [
        {
          "name": "stdout",
          "text": [
            "The model has 2,592,105 trainable parameters",
            "\n"
          ],
          "output_type": "stream"
        }
      ],
      "source": "def count_parameters(model):\n    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n\nprint(f\u0027The model has {count_parameters(model):,} trainable parameters\u0027)",
      "metadata": {
        "pycharm": {
          "metadata": false,
          "name": "#%%\n",
          "is_executing": false
        }
      }
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "outputs": [
        {
          "name": "stdout",
          "text": [
            "2592105",
            "\n"
          ],
          "output_type": "stream"
        }
      ],
      "source": "print(INPUT_DIM*EMBEDDING_DIM+# x_t -\u003e i_t\n      EMBEDDING_DIM*HIDDEN_DIM+HIDDEN_DIM+ # i_t -\u003e h_t \n      HIDDEN_DIM*HIDDEN_DIM+HIDDEN_DIM+ # h_(t-1) -\u003e h_t\n      HIDDEN_DIM*OUTPUT_DIM+OUTPUT_DIM) # h_t -\u003e o_t",
      "metadata": {
        "pycharm": {
          "metadata": false,
          "name": "#%%\n",
          "is_executing": false
        }
      }
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "outputs": [],
      "source": "import torch.optim as optim\n\noptimizer \u003d optim.SGD(model.parameters(), lr\u003d1e-3)\ncriterion \u003d nn.BCEWithLogitsLoss()",
      "metadata": {
        "pycharm": {
          "metadata": false,
          "name": "#%%\n",
          "is_executing": false
        }
      }
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "outputs": [],
      "source": "def binary_accuracy(preds, y):\n    \"\"\"\n    Returns accuracy per batch, i.e. if you get 8/10 right, this returns 0.8, NOT 8\n    \"\"\"\n\n    #round predictions to the closest integer\n    rounded_preds \u003d torch.round(torch.sigmoid(preds))\n    correct \u003d (rounded_preds \u003d\u003d y).float() #convert into float for division \n    acc \u003d correct.sum() / len(correct)\n    return acc",
      "metadata": {
        "pycharm": {
          "metadata": false,
          "name": "#%%\n",
          "is_executing": false
        }
      }
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "outputs": [],
      "source": "def train(model, iterator, optimizer, criterion):\n    \n    epoch_loss \u003d 0\n    epoch_acc \u003d 0\n    \n    model.train()\n    \n    for batch in iterator:\n        \n        optimizer.zero_grad()\n                \n        predictions \u003d model(batch.text).squeeze(1)\n        \n        loss \u003d criterion(predictions, batch.label)\n        \n        acc \u003d binary_accuracy(predictions, batch.label)\n        \n        loss.backward()\n        \n        optimizer.step()\n        \n        epoch_loss +\u003d loss.item()\n        epoch_acc +\u003d acc.item()\n        \n    return epoch_loss / len(iterator), epoch_acc / len(iterator)",
      "metadata": {
        "pycharm": {
          "metadata": false,
          "name": "#%%\n",
          "is_executing": false
        }
      }
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "outputs": [],
      "source": "def evaluate(model, iterator, criterion):\n    \n    epoch_loss \u003d 0\n    epoch_acc \u003d 0\n    \n    model.eval()\n    \n    with torch.no_grad():\n    \n        for batch in iterator:\n\n            predictions \u003d model(batch.text).squeeze(1)\n            \n            loss \u003d criterion(predictions, batch.label)\n            \n            acc \u003d binary_accuracy(predictions, batch.label)\n\n            epoch_loss +\u003d loss.item()\n            epoch_acc +\u003d acc.item()\n        \n    return epoch_loss / len(iterator), epoch_acc / len(iterator)",
      "metadata": {
        "pycharm": {
          "metadata": false,
          "name": "#%%\n",
          "is_executing": false
        }
      }
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "outputs": [
        {
          "name": "stdout",
          "text": [
            "torch.Size([843, 64])",
            " ",
            "tensor([[ 1476,   309,    10,  ...,    45,    10, 16608],\n        [   10,    48,    14,  ...,   521,     7,  3522],\n        [   20,    63,   200,  ...,    98,    31,     0],\n        ...,\n        [    1,     1,     1,  ...,     1,     1,     1],\n        [    1,     1,     1,  ...,     1,     1,     1],\n        [    1,     1,     1,  ...,     1,     1,     1]])",
            "\n",
            "torch.Size([64])",
            " ",
            "tensor([1., 0., 0., 1., 0., 0., 0., 1., 1., 0., 1., 0., 0., 0., 0., 1., 0., 0.,\n        0., 0., 0., 1., 1., 1., 0., 1., 0., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n        0., 0., 0., 1., 0., 1., 0., 1., 1., 1., 0., 0., 0., 0., 1., 0., 1., 0.,\n        0., 0., 1., 1., 0., 1., 1., 1., 0., 1.])",
            "\n"
          ],
          "output_type": "stream"
        }
      ],
      "source": "sample_data \u003d iter(train_iterator).__next__()\nprint(sample_data.text.shape, sample_data.text)\nprint(sample_data.label.shape, sample_data.label)",
      "metadata": {
        "pycharm": {
          "metadata": false,
          "name": "#%%\n",
          "is_executing": false
        }
      }
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "outputs": [],
      "source": "import time\n\ndef epoch_time(start_time, end_time):\n    elapsed_time \u003d end_time - start_time\n    elapsed_mins \u003d int(elapsed_time / 60)\n    elapsed_secs \u003d int(elapsed_time - (elapsed_mins * 60))\n    return elapsed_mins, elapsed_secs",
      "metadata": {
        "pycharm": {
          "metadata": false,
          "name": "#%%\n",
          "is_executing": false
        }
      }
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "outputs": [
        {
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[1;32m\u003cipython-input-41-18c4bbde3ebb\u003e\u001b[0m in \u001b[0;36m\u003cmodule\u003e\u001b[1;34m\u001b[0m\n\u001b[0;32m      7\u001b[0m     \u001b[0mstart_time\u001b[0m \u001b[1;33m\u003d\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----\u003e 9\u001b[1;33m     \u001b[0mtrain_loss\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_acc\u001b[0m \u001b[1;33m\u003d\u001b[0m \u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_iterator\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     10\u001b[0m     \u001b[0mvalid_loss\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalid_acc\u001b[0m \u001b[1;33m\u003d\u001b[0m \u001b[0mevaluate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalid_iterator\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32m\u003cipython-input-37-cd15a9d80420\u003e\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(model, iterator, optimizer, criterion)\u001b[0m\n\u001b[0;32m     16\u001b[0m         \u001b[0macc\u001b[0m \u001b[1;33m\u003d\u001b[0m \u001b[0mbinary_accuracy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpredictions\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlabel\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---\u003e 18\u001b[1;33m         \u001b[0mloss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     19\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     20\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32mF:\\anaconda3.7\\lib\\site-packages\\torch\\tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[1;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[0;32m    100\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[1;33m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    101\u001b[0m         \"\"\"\n\u001b[1;32m--\u003e 102\u001b[1;33m         \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    103\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    104\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;32mF:\\anaconda3.7\\lib\\site-packages\\torch\\autograd\\__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[0;32m     88\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[0;32m     89\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---\u003e 90\u001b[1;33m         allow_unreachable\u003dTrue)  # allow_unreachable flag\n\u001b[0m\u001b[0;32m     91\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     92\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
            "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
          ],
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error"
        }
      ],
      "source": "N_EPOCHS \u003d 5\n\nbest_valid_loss \u003d float(\u0027inf\u0027)\n\nfor epoch in range(N_EPOCHS):\n\n    start_time \u003d time.time()\n    \n    train_loss, train_acc \u003d train(model, train_iterator, optimizer, criterion)\n    valid_loss, valid_acc \u003d evaluate(model, valid_iterator, criterion)\n    \n    end_time \u003d time.time()\n\n    epoch_mins, epoch_secs \u003d epoch_time(start_time, end_time)\n    \n    if valid_loss \u003c best_valid_loss:\n        best_valid_loss \u003d valid_loss\n        torch.save(model.state_dict(), \u0027tut1-model.pt\u0027)\n    \n    print(f\u0027Epoch: {epoch+1:02} | Epoch Time: {epoch_mins}m {epoch_secs}s\u0027)\n    print(f\u0027\\tTrain Loss: {train_loss:.3f} | Train Acc: {train_acc*100:.2f}%\u0027)\n    print(f\u0027\\t Val. Loss: {valid_loss:.3f} |  Val. Acc: {valid_acc*100:.2f}%\u0027)",
      "metadata": {
        "pycharm": {
          "metadata": false,
          "name": "#%%\n",
          "is_executing": false
        }
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": "model.load_state_dict(torch.load(\u0027tut1-model.pt\u0027))\n\ntest_loss, test_acc \u003d evaluate(model, test_iterator, criterion)\n\nprint(f\u0027Test Loss: {test_loss:.3f} | Test Acc: {test_acc*100:.2f}%\u0027)\n",
      "metadata": {
        "pycharm": {
          "metadata": false,
          "name": "#%%\n"
        }
      }
    }
  ],
  "metadata": {
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 2
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython2",
      "version": "2.7.6"
    },
    "kernelspec": {
      "name": "python3",
      "language": "python",
      "display_name": "Python 3"
    },
    "stem_cell": {
      "cell_type": "raw",
      "source": "",
      "metadata": {
        "pycharm": {
          "metadata": false
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}